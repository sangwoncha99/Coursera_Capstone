{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# 1. Introduction"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 1.1 Background\n\nMotor vehicles accidents in the United States continue to affect the lives hundreds of thousands of people - not only victims themselves but also their families and loved ones. According to data published by the National Highway Traffic Safety Administration, average fatality from vehicle accidents from 2014 to 2018, 36,013, is actually lower than that of from 1995 to 1999, 41,822. Make no mistake, that is still a high figure. The statistic shows even with advent of technology aimed to produce safer cars and tougher drivers' license requirements, tragic car accidents inflict so much pain both mentally and physically. Then what exactly causes fatalities and injuries in car accidents and to what extent does that cause(s) affect the severity of an accident? \n\nIn reality, there are so many variables that affect severity - number of people involved, presence of pedestrians and motorcyclists, direction from which car came from, the speed of car before accident, and so many more. Therefore, when emergency responders are on site of accident, it is practically impossible to communicate all information regarding the situation with every single detail, especially when few seconds can be the difference between life and death. A prediction that summarizes all of these variables into a single metric would not only guide emergency responders and medical staff to make more informed and better decisions on treatment but also in the long run give policy makers a better idea about formulating legislation that aims to eliminate possible factors contributing to severity of accidents."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 1.2 Problem\n\nThis project aims to develop a program that predicts the severity of an accident based on data collected by local authorities and will focus on data from Seattle, Washington."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 1.3 Interest\n\nThe groups of people that benefit greatly from severity predictions would be: a) emergency responders and emergency room staff (doctors and nurses) because the prediction would provide general guidance on treatment approaches, and b) policy makers because they can reference in which conditions severity increased and accordingly pass legislation for traffic regulations, safer infrastructure, and other safety measures. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# 2. Data\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2.1 Data Source\n\nThe data is on accidents collected on Seattle, Washington, which was obtained from [here.](https://www.kaggle.com/jonleon/seattle-sdot-collisions-data/)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2.2 Data Cleaning\n\nThere were some problems that needed to be addressed within the dataset. First, some instances contained not enough information in order to reach a meaningful severity prediction. For example, EXCEPTRSNCODE entry value of instance of OBJECTID 421 is 'NEI', abbreviation for 'not enough information.' PERSONCOUNT,  PEDCOUNT, PEDCYLCOUNT, and VEHCOUNT for this instance were all 0. Thus, instances like that of OBJECTID 421 were discarded from the data. \n\nOn the other hand, however, there were instances whose at least one entry value for PERSONCOUNT,  PEDCOUNT, PEDCYLCOUNT, and VEHCOUNT was non-zero, but description of collision conveyed by ST_COLDESC was not logically consistent with the four aforementioned features. A notable example of such instance is that of OBJEICD 328 and 329. ST_COLDESC of both instances describe a motor vehicle colliding with another motor vehicle, but VEHCOUNT were 0 for both of them. Instances of OBJECTID 328, 329, and 421 all share a common trait: their STATUS entry values were 'Unmatched'. It was to this premise that I decided to drop all instances of STATUS 'Unmatched.' \n\nHowever, doing so did not completely eliminate all instances described above. Consequently, I also dropped instances of EXCEPTRSNCODE 'NEI' and of SDOT_COLDESC 'NOT ENOUGH INFORMATION / NOT APPLICABLE'. After cleaning the data, I was left with 185242 instances. \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2.3 Feature Selection\n\nThe cleaned data contains 40 features. First, I took the liberty of dropping features that were left blank - most notably EXCEPTRSNCODE and EXCEPTRSNDESC. These two features, at its raw form, were initially not empty.\n\nSecond, features that contributed little or none at all in predicting severity were dropped. There were few general categories of such features. One of which is unique codes assigned by state authorities according to their guidelines. Some features that fell into this categories were: OBJECTID, SHAPE, STATUS, COLDETKEY, REPORTNO, SEGLANEKEY, CROSSWALKKEY, INCKEY, and INTKEY, and SDOTCOLNUM.\n\nAnother category was features that described circumstances not directly pertinent to accidents themselves. Features comprising this category were: LOCATION, ADDRTYPE, X,and Y (which are respectively the longitude and the latitude of accidents).\n\nThe final category was features whose information was redundant. Those were INCDATE and INCDTTM. My initial assumptions after looking through were that precipitation (such as rain, snow, and sleet) and amount of light (bright, cloudy, dark, etc) would contribute to severity and that therefore I would need to gather weather data. However, upon further inspection, I realized that such information were conveyed by WEATHER, ROADCOND, and LIGHTCOND. Another set of features were redundant. SDOT_COLCODE, SDOT_COLDESC, ST_COLCODE, and ST_COLDESC. The SDOT features more or less convey the same information as their ST counterparts, except that they use different labels. After comparing SDOT and ST features, I concluded that SDOT features offered entry values that were more favorable to data analysis. Therefore, ST features were dropped. Also, COLLISIONTYPE also contains overlapping information so it was dropped as well. SEVERITYDESC, which simply describe what the entry values of SEVERITYCODE mean, essentially overlaps with SEVERITYCODE, so it was also dropped. Also, INJURIES, SERIOUSINJURIES, and FATALITIES collide with SEVERITYCODE, for SEVERITYCODE in fact reflects whether there were any fatalities and injuries. \n\nJust to make sure I went through the data if there were any more features I could eliminate. Noticing that COLLISIONTYPE and HITPARKEDCAR conveyed similar information, I cross-referenced the two features to see if there were any inconsistencies and immediately noticed there were. For example, instances of OBJECTID 23 and 24 involved parked cars, but their HITPARKEDCAR entry values are both 'N'. Therefore, without much futher inspection, I decided to drop HITPARKEDCAR. \n\nAfter dropping features according to the procedure outlined above, following features remained: SEVERITYCODE, PERSONCOUNT, PEDCOUNT, PEDCYLCOUNT, VEHCOUNT, SDOT_COLCODE, SDOT_COLDESC, INATTENTIONIND, UNDERINFL, WEATHER, ROADCOND, LIGHTCOND, PEDROWNOTGRNT, SPEEDING, INJURIES, SERIOUSINJURIES, and FATALITIES.\n\nI will be using two models in this project: regression and classification. Regression will be used to predict the number of fatalities (not injuries), corresponding to FATALITIES feature, and classification to predict severity of an accident, corresponding to SEVERITYCODE. Not all features will be actively used in the data analysis procedure. SDOT_COLDESC will be used as reference in order to help construct a mental image of the actual collisions. It must be noted that SDOT_COLCODE is not a numerical variable, but a categorical variable. As a result, I will use One Hot Encoding technique to convert SDOT_COLCODE to a numerical variable, which is more easily digestible for analysis. All features other than the aforementioned target variables will be used in regression and classification models. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# 3. Methodology\n\nThe overall direction of this project will be figuring out which set of parameters for the classification models will result in maximum accuracies - i.e. which k-value for K-Nearest Neighbors, what depth for decision tree classifier, and what solver and what multi-classifier parameter in logistic regresssion, and which kernel for SVM. Numerous features in the dataset are not numerical variables, which is not appropriate for classification models used in this report. I will use One Hot Encoding Technique to quantify those features. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# 4. Analysis\n\nPlease refer to Coursera_Capstone notebook for this section."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# 5. Discussion and Results\n\nIn this project, I calculated Jaccard similarity score, F1 score, and log loss (only when applicable) for four classification models, K-nearest neighbors, decision tree classifier, logistic regression, and SVM, after optimizing accuracy with respect to various parameters. K = 12 resulted in maximum accuracy for K-nearest neighbors, depth of 22 for decision tree classifier, 'multi_class' of 'multinomial' for logistic regression, and 'linear' kernel for SVM, given the feature set. \n\nFigure 5 shows Jaccard similarity scores, F1 scores, and log loss (of only logistic regression) of the four classification models created in this project. It is noteworthy in Figure 5 that decision tree classifier resulted in the greatest Jaccard similarity score and F1 score among the four classification models, followed by K-nearest neighbors, logistic regression, and SVM. \n\nThe confusion matrices - Figures 1, 2, 3, and 4 - show us a closer look at predictions made by models created in this project. Across the board, the models show very good accuracy in predicting instances with SEVERITYCODE = 0, with Figures 1b, 2b, 3b, and 4b showing a ratio of 1.0. The reason for this almost too-good-to-be-true result, however, I believe, is there is a lurking variable that I overlooked while selecting and modifying features. I suspect that the two 'Unknown' features, each originating from features LIGHTCOND and ROADCOND of the raw data, may have impacted and possibly served as a direct indicator of SEVERITYCODE, which I aimed to eliminate such features during the process of cleaning raw data. This suspicion is quite feasible because I noticed a tendency in which instances whose features containing 'Unknown', 'NEI', or 'Not Enough Information' as their entry values were assigned SEVERITYCODE of 0. In hindsight, it would have been a better call to exclude instances with SEVERITYCODE of 0 from the dataset.\n\nFortunately enough, severity predictions on other classes, 1, 2, 2b, and 3, show much more realistic ratios. The results in all four models demonstrate the models are better at predicting severity than simply randomly guessing in which case the ratio of correct predictions is 0.2. The models also show fairly accurate predictions on instances with SEVERITYCODE = 3, those that actually resulted in fatality and also instances of SEVERITYCODE = 1. \n\nHowever, the confusion matrices demonstrate the models are not very good at distinguishing between instances of 2 and 2b - those that result in injuries and severe injuries. In other words, it cannot necessarily predict the severity of injuries. The figures show instances of SEVERITYCODE 2 were most often misclassified as SEVERITYCODE 1 and instances of SEVERITYCODE 2b as 3. So accidents that would result in injuries were underestimated as resulting in only property damage with no injuries while accidents resulting in severe injuries were overestimated as resulting in deaths. It is worrisome that if in the case where first responders were to use the models developed in this project, then they would be misled by underestimation of the models. On the other hand, if one were to take an optimistic view of the models' overestimation, he or she could make the point that first responders would stay more vigilant regarding the patients' conditions. Regardless of these pros and cons, the ideal scenario, of course, would be in which any misclassifications do not occur. \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# 6. Conclusion\n\nIn this project, I aimed to develop classification models that preidct severity of motor vehicle accidents using data about circumstances of the accidents. I quantified all categorical variables using the One Hot Encoding technique and programmed to find parameters that result in the greatest accuracy possible for four classification methods: k-nearest neighbors, decision tree, logistic regression, and SVM. It was my hope, at the beginning of the project, the models would turn out to be useful for first responders and medical staff in reinforcing their understanding of severity of the patients' injuries.\n\nIdeally, stakeholders of this project, first responders and medical staff, will take into consideration more factors other than those used in this project when assessing the patients' conditions if they want a more accurate severity prediction such as type of car rode by driver, any protective equipment worn by pedalcyclist or pedestrian, activation of any safety systems within car, and speed at which collision occurred. More comprehensive and refined versions of these models predicting severity would not only help first responders and medical staff save lives in the short term, but also policy makers save many more in the long term by creating safer environments."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}